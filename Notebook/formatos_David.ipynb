{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook con script para Generar formato para Docentes a partir de la Nomina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Condiciones iniciales para trabajar con pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 3000)\n",
    "pd.set_option('display.max_rows', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carpeta donde esta ubicado la informacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/bane/notebook/David/'\n",
      "/home/bane/anaconda3/envs/sist-const-senifa/django_project/Notebook\n"
     ]
    }
   ],
   "source": [
    "cd ~/notebook/David/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Funcion para Ubicar los archivos de cada quincena para un mes en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quincenas(carp1, arch1, arch2):\n",
    "    df1 = pd.read_csv(f'{carp1}{arch1}.csv', sep=';',\n",
    "                  usecols=['CEDULA','APELLIDO Y NOMBRE', 'Unnamed: 2', 'CARGO', \n",
    "                           'UBICACIÓN GEOGRAFICA',  'Unnamed: 9', 'Unnamed: 10', ' ',\n",
    "                           'NETO A PAGAR'])\n",
    "    df2 = pd.read_csv(f'{carp1}{arch2}.csv', sep=';',\n",
    "                      usecols=['CEDULA','APELLIDO Y NOMBRE', 'Unnamed: 2', 'CARGO', 'NETO A PAGAR'])\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Funcion para Renombrar y Seleccionar las Columnas de la tabla.\n",
    "Partimos de la primera quincena para generar la mayoria de la información necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Renom_Selecc1(df1):\n",
    "    df1.rename(columns={\"CEDULA\":\"Cedula\", \"APELLIDO Y NOMBRE\":\"Apellido\", \"Unnamed: 2\":\"Nombre\", \n",
    "                       \"CARGO\":\"Cargo\", \"UBICACIÓN GEOGRAFICA\":\"Ubicación\", \"Unnamed: 10\":\"Año\", \"Unnamed: 9\":\"Mes\", \n",
    "                       \" \":\"Dia\", \"NETO A PAGAR\":\"1era Quincena\",}, inplace=True)\n",
    "    df1 = df1.loc[:, ['Cedula', 'Apellido', 'Nombre', 'Cargo', 'Ubicación', \n",
    "                      'Año', 'Mes', 'Dia', '1era Quincena']]        \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Funcion para Reorganizar la fecha en la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organiz_Fechas(df1):\n",
    "    dfA = df1.loc[:, ['Año', 'Mes', 'Dia']]\n",
    "    dfA['Año'] = dfA['Año'].astype('string')\n",
    "    dfA['Mes'] = dfA['Mes'].astype('string')\n",
    "    dfA['Dia'] = dfA['Dia'].astype('string')\n",
    "    df1['Fecha de Ingreso'] = dfA['Año'] + '-' + dfA['Mes'] + '-' + dfA['Dia']\n",
    "    df1['Fecha de Ingreso'] = pd.to_datetime(df1['Fecha de Ingreso'], format='%Y/%m/%d')\n",
    "    del dfA\n",
    "    df1 = df1.loc[:, ['Cedula', 'Apellido', 'Nombre', 'Cargo', 'Ubicación', \n",
    "                      'Fecha de Ingreso', '1era Quincena']]\n",
    "    df1['1era Quincena'] = df1['1era Quincena'].str.replace(',', '.').astype(float)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Funcion para Renombrar y Seleccionar las columnas de la segunda quincena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Renom_Selecc2(df2):\n",
    "    df2.rename(columns={\"CEDULA\":\"Cedula\", \"APELLIDO Y NOMBRE\":\"Apellido\", \"Unnamed: 2\":\"Nombre\", \n",
    "                       \"CARGO\":\"Cargo\", \"UBICACIÓN GEOGRAFICA\":\"Ubicación\", \n",
    "                       \"NETO A PAGAR\":\"2da Quincena\",}, inplace=True)\n",
    "    df2 = df2.loc[:, ['Cedula', 'Apellido', 'Nombre', 'Cargo', '2da Quincena']]\n",
    "    df2['2da Quincena'] = df2['2da Quincena'].str.replace(',', '.').astype(float)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Funcion para Comprobar transcripcion de datos previo union de ambas tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp_transcrip(df1, df2):\n",
    "    diff_cedula = df1['Cedula'].equals(df2['Cedula'])\n",
    "    diff_Apellido = df1['Apellido'].equals(df2['Apellido'])\n",
    "    diff_Nombre = df1['Nombre'].equals(df2['Nombre'])\n",
    "    diff_Cargo = df1['Cargo'].equals(df2['Cargo'])\n",
    "    diferencia = {'diff_cedula':diff_cedula, 'diff_Apellido':diff_Apellido, \n",
    "              'diff_Nombre':diff_Nombre, 'diff_Cargo':diff_Cargo}\n",
    "    for i in range(0,len(diferencia)):\n",
    "        if list(diferencia.values())[i] == True:\n",
    "            print(f'Sin problemas en la Columna {df1.columns[i]}')\n",
    "        else:\n",
    "            print(f'Se observaron diferencias en las celdas de la Columna {df1.columns[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Funcion para Unir tablas y Generar monto total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Monto_total(df1, df2):\n",
    "    df1 = df1.reset_index()\n",
    "    df2 = df2.reset_index()\n",
    "    df1 = df1.loc[:, ['Cedula', 'Apellido', 'Nombre', 'Cargo', 'Ubicación', \n",
    "                      'Fecha de Ingreso', '1era Quincena']]        \n",
    "    df1 = df1.set_index('Cedula')\n",
    "    df2 = df2.loc[:, ['Cedula', '2da Quincena']]\n",
    "    df2 = df2.set_index('Cedula')\n",
    "    df1['2da Quincena'] = df2['2da Quincena']\n",
    "    df1['total'] = df1['1era Quincena'] + df1['2da Quincena']\n",
    "    del df2\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Funcion para separar Madres Comunitarias del resto de la Nomina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Separar_madres(df1):\n",
    "    mask = df1['Cargo'] == 'MADRE COMUNITARIA'\n",
    "    df1 = df1.loc[mask]\n",
    "    df2 = df1.loc[mask==False]\n",
    "    #display(df1.head(), df1.info())\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resultados_Docentes(carp1, arch1, arch2, arch3, arch4):\n",
    "    tabla1, tabla2 = Quincenas(carp1, arch1, arch2)\n",
    "    ### Primero creamos las dos tablas con los datos de los archivos con las quincenas.\n",
    "    tabla1 = Renom_Selecc1(tabla1)         ### Renombranos las columnas tabla 1.\n",
    "    tabla1 = Organiz_Fechas(tabla1)        ### Reorganizamos la fecha en la tabla 1.\n",
    "    tabla2 = Renom_Selecc2(tabla2)         ### Renombranos y seleccionamos las columnas tabla 2.\n",
    "    Comp_transcrip(tabla1, tabla2)         ### Comprobacion de transcripcion antes de unir ambas tablas.\n",
    "    tabla = Monto_total(tabla1, tabla2)    ### Generacion de tabla final con la información deseada.\n",
    "    tabla1, tabla2 = Separar_madres(tabla) ### Funcion para separar las madres de la nomina.\n",
    "    tabla1.to_csv(f'{carp1}{arch3}.csv', sep=';')\n",
    "    print(f'Generado archivo {arch3}.csv en la carpeta {carp1}')\n",
    "    tabla2.to_csv(f'{carp1}{arch4}.csv', sep=';')\n",
    "    print(f'Generado archivo {arch4}.csv en la carpeta {carp1}')\n",
    "    del tabla, tabla1, tabla2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Funcion para generacion de archivo con la informacion solicitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['Unnamed: 10', ' ', 'Unnamed: 9']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0ba919eba286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0march3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Resultados Madres 2020 ENE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0march4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Resultados Docentes 2020 ENE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mResultados_Docentes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-bc61f7e78334>\u001b[0m in \u001b[0;36mResultados_Docentes\u001b[0;34m(carp1, arch1, arch2, arch3, arch4)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mResultados_Docentes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtabla1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabla2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuincenas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m### Primero creamos las dos tablas con los datos de los archivos con las quincenas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtabla1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRenom_Selecc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabla1\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m### Renombranos las columnas tabla 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtabla1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrganiz_Fechas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabla1\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m### Reorganizamos la fecha en la tabla 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c85d4899b1f8>\u001b[0m in \u001b[0;36mQuincenas\u001b[0;34m(carp1, arch1, arch2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mQuincenas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     df1 = pd.read_csv(f'{carp1}{arch1}.csv', sep=';',\n\u001b[0m\u001b[1;32m      3\u001b[0m                   usecols=['CEDULA','APELLIDO Y NOMBRE', 'Unnamed: 2', 'CARGO', \n\u001b[1;32m      4\u001b[0m                            \u001b[0;34m'UBICACIÓN GEOGRAFICA'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'Unnamed: 9'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unnamed: 10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            'NETO A PAGAR'])\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterhub/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterhub/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterhub/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterhub/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterhub/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1942\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m             ):\n\u001b[0;32m-> 1944\u001b[0;31m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterhub/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[0;34m(usecols, names)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;34mf\"Usecols do not match columns, columns expected but not found: {missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['Unnamed: 10', ' ', 'Unnamed: 9']"
     ]
    }
   ],
   "source": [
    "carp1 = 'Datos/'\n",
    "arch1 = 'Informacion_RRHH_1era_quincena'\n",
    "arch2 = 'Informacion_RRHH_2da_quincena'\n",
    "arch3 = 'Resultados Madres 2020 ENE'\n",
    "arch4 = 'Resultados Docentes 2020 ENE'\n",
    "Resultados_Docentes(carp1, arch1, arch2, arch3, arch4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f'{carp1}{arch1}.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f'{carp1}{arch1}.csv', sep=';',\n",
    "                  usecols=['CEDULA','APELLIDO Y NOMBRE', 'Unnamed: 2', 'CARGO', \n",
    "                           'UBICACIÓN GEOGRAFICA',  'Unnamed: 9', 'Unnamed: 10', ' ',\n",
    "                           'NETO A PAGAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
